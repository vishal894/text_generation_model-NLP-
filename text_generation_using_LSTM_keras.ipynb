{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text generation using LSTM_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLxLcvQ5gcOJ4Sm15G0uBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishal894/text_generation_model-NLP-/blob/main/text_generation_using_LSTM_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRoDFxplF-ph"
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxH9N4nPGaHf"
      },
      "source": [
        "response=requests.get('https://raw.githubusercontent.com/laxmimerit/poetry-data/master/adele.txt')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_kpPtRaHbF1"
      },
      "source": [
        "#response.text"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxXJftNaHgTS"
      },
      "source": [
        "data=response.text.split('\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs0-Rjenhk9c",
        "outputId": "d2e75d5b-57b8-4fe0-d792-26a40cec2a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Looking for some education'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb2-4KMxhnN9",
        "outputId": "f9452fc0-3fb2-4b30-f3e3-71e6de585b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data[8]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"If that's love in your eyes\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAMRUT4thpzo"
      },
      "source": [
        "data=\" \".join(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MepLnfwuiI2S"
      },
      "source": [
        ""
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_SuOFp_iKGG"
      },
      "source": [
        "## Remove punctuation from data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81mMZpmwmpsj"
      },
      "source": [
        "import re"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX3p4ORWmoG5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZTnjjEIiVAK"
      },
      "source": [
        "def data_clean(data):\n",
        "  tokens=data.split()\n",
        "  #tokens=str.maketrans('','',string.punctuation)\n",
        "  punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "  #if tokens in punc:\n",
        "    #tokens = tokens.replace(tokens, \"\")    \n",
        "  #tokens=[w.translate(table) for w in tokens]\n",
        "  tokens=[word for word in tokens if word.isalpha()]\n",
        "  tokens=[word.lower() for word in tokens]\n",
        "  return tokens\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f22TCCotjxZ3"
      },
      "source": [
        "tokens=data_clean(data)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0z66YjTj3pc"
      },
      "source": [
        "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "for token in tokens:\n",
        "  if token in punc:\n",
        "    tokens=tokens.replace(token,\"\")\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZF5CK4wnxha",
        "outputId": "d06c7584-aca0-4b41-d4c9-1de5e8a19f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1yx34Wfpurd"
      },
      "source": [
        "vec_dim=len(set(tokens))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rim_YMlspyWw"
      },
      "source": [
        "max_length=20+1\n",
        "lines=[]\n",
        "for i in range(max_length,len(tokens)):\n",
        "  seq=tokens[i-max_length:i]\n",
        "  line=' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i>2000:\n",
        "    break;\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQYQ8ji0rh7U",
        "outputId": "a27ed28c-36b0-4e52-da6b-5d4ab0c83fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(lines))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrauKEnrly0",
        "outputId": "dfacee2b-aafa-4689-845e-0a930a7e510b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'looking for some education made my way into the night all that bullshit conversation you read the i bore you with'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyOZdQZtroUH"
      },
      "source": [
        "import  numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdWdemJoHWXh"
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_5tlM-CHwGd",
        "outputId": "0946fa09-96e6-4cff-ddbb-9f6dfd5e6cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokenizer.word_index\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 19,\n",
              " 'about': 205,\n",
              " 'absence': 229,\n",
              " 'affirmation': 222,\n",
              " 'after': 305,\n",
              " 'all': 16,\n",
              " 'almost': 202,\n",
              " 'already': 216,\n",
              " 'always': 120,\n",
              " 'and': 6,\n",
              " 'anymore': 58,\n",
              " 'apart': 153,\n",
              " 'are': 27,\n",
              " 'arms': 363,\n",
              " 'as': 69,\n",
              " 'ask': 154,\n",
              " 'asking': 349,\n",
              " 'at': 88,\n",
              " 'babies': 227,\n",
              " 'baby': 28,\n",
              " 'back': 184,\n",
              " 'bad': 170,\n",
              " 'bare': 197,\n",
              " 'be': 30,\n",
              " 'beat': 138,\n",
              " 'beating': 289,\n",
              " 'been': 333,\n",
              " 'before': 207,\n",
              " 'best': 110,\n",
              " 'better': 372,\n",
              " 'between': 322,\n",
              " 'bittersweet': 272,\n",
              " 'blessings': 295,\n",
              " 'blue': 180,\n",
              " 'bore': 221,\n",
              " 'born': 259,\n",
              " 'both': 330,\n",
              " 'bound': 263,\n",
              " 'bread': 177,\n",
              " 'breaking': 150,\n",
              " 'breathless': 203,\n",
              " 'bringing': 194,\n",
              " 'bullshit': 385,\n",
              " 'burn': 124,\n",
              " 'but': 12,\n",
              " 'by': 38,\n",
              " 'california': 314,\n",
              " 'call': 145,\n",
              " 'called': 142,\n",
              " 'calling': 234,\n",
              " 'came': 249,\n",
              " 'can': 22,\n",
              " 'cares': 268,\n",
              " 'caught': 379,\n",
              " 'cause': 373,\n",
              " 'claim': 352,\n",
              " 'clear': 275,\n",
              " 'clearly': 151,\n",
              " 'close': 368,\n",
              " 'clothes': 240,\n",
              " 'coming': 337,\n",
              " 'conversation': 384,\n",
              " 'could': 40,\n",
              " 'count': 294,\n",
              " 'cried': 374,\n",
              " 'cruel': 347,\n",
              " 'cry': 366,\n",
              " 'crystal': 274,\n",
              " 'cupid': 232,\n",
              " 'dark': 136,\n",
              " 'day': 238,\n",
              " 'days': 266,\n",
              " 'deep': 86,\n",
              " 'depths': 285,\n",
              " 'despair': 286,\n",
              " 'did': 327,\n",
              " 'difference': 321,\n",
              " 'do': 31,\n",
              " 'done': 118,\n",
              " 'door': 140,\n",
              " 'down': 181,\n",
              " 'dreaming': 315,\n",
              " 'dreams': 248,\n",
              " 'ease': 167,\n",
              " 'education': 386,\n",
              " 'ends': 160,\n",
              " 'enough': 169,\n",
              " 'even': 125,\n",
              " 'ever': 210,\n",
              " 'every': 198,\n",
              " 'everything': 117,\n",
              " 'eyes': 72,\n",
              " 'face': 94,\n",
              " 'falling': 365,\n",
              " 'far': 359,\n",
              " 'fast': 99,\n",
              " 'fed': 178,\n",
              " 'feel': 369,\n",
              " 'feeling': 204,\n",
              " 'feet': 209,\n",
              " 'fell': 208,\n",
              " 'felt': 206,\n",
              " 'fever': 193,\n",
              " 'fight': 187,\n",
              " 'finally': 273,\n",
              " 'find': 80,\n",
              " 'fire': 68,\n",
              " 'flames': 376,\n",
              " 'flies': 256,\n",
              " 'for': 20,\n",
              " 'forever': 370,\n",
              " 'forget': 111,\n",
              " 'forgiveness': 350,\n",
              " 'forgotten': 319,\n",
              " 'found': 246,\n",
              " 'free': 318,\n",
              " 'friend': 155,\n",
              " 'friends': 224,\n",
              " 'from': 48,\n",
              " 'fun': 228,\n",
              " 'games': 217,\n",
              " 'gave': 252,\n",
              " 'get': 213,\n",
              " 'gets': 371,\n",
              " 'girl': 128,\n",
              " 'give': 62,\n",
              " 'glory': 265,\n",
              " 'go': 137,\n",
              " 'gold': 299,\n",
              " 'gonna': 18,\n",
              " 'got': 126,\n",
              " 'guess': 250,\n",
              " 'had': 13,\n",
              " 'hand': 51,\n",
              " 'happy': 243,\n",
              " 'hate': 185,\n",
              " 'have': 41,\n",
              " 'having': 171,\n",
              " 'haze': 262,\n",
              " 'head': 283,\n",
              " 'heal': 310,\n",
              " 'healing': 313,\n",
              " 'hear': 127,\n",
              " 'heard': 78,\n",
              " 'heart': 34,\n",
              " 'hello': 67,\n",
              " 'help': 71,\n",
              " 'hide': 254,\n",
              " 'his': 235,\n",
              " 'hold': 107,\n",
              " 'home': 116,\n",
              " 'honesty': 341,\n",
              " 'hope': 326,\n",
              " 'hoped': 188,\n",
              " 'how': 49,\n",
              " 'hurts': 64,\n",
              " 'i': 1,\n",
              " 'if': 33,\n",
              " 'in': 8,\n",
              " 'indoors': 241,\n",
              " 'inside': 87,\n",
              " 'instead': 83,\n",
              " 'into': 93,\n",
              " 'is': 25,\n",
              " 'it': 5,\n",
              " 'just': 26,\n",
              " 'keep': 102,\n",
              " 'keeps': 233,\n",
              " 'kind': 301,\n",
              " 'kissed': 354,\n",
              " 'knees': 358,\n",
              " 'knew': 161,\n",
              " 'know': 61,\n",
              " 'known': 271,\n",
              " 'knows': 343,\n",
              " 'ladies': 226,\n",
              " 'last': 90,\n",
              " 'lasts': 63,\n",
              " 'lay': 196,\n",
              " 'laying': 367,\n",
              " 'least': 148,\n",
              " 'leave': 114,\n",
              " 'left': 339,\n",
              " 'lesson': 346,\n",
              " 'let': 70,\n",
              " 'light': 255,\n",
              " 'like': 39,\n",
              " 'lips': 355,\n",
              " 'lives': 258,\n",
              " 'look': 296,\n",
              " 'looking': 96,\n",
              " 'love': 15,\n",
              " 'lovers': 159,\n",
              " 'loving': 174,\n",
              " 'made': 123,\n",
              " 'make': 37,\n",
              " 'making': 242,\n",
              " 'married': 247,\n",
              " 'matters': 119,\n",
              " 'maybe': 166,\n",
              " 'me': 10,\n",
              " 'meet': 308,\n",
              " 'memories': 270,\n",
              " 'memory': 156,\n",
              " 'met': 35,\n",
              " 'miles': 324,\n",
              " 'million': 323,\n",
              " 'mind': 98,\n",
              " 'mine': 287,\n",
              " 'miss': 76,\n",
              " 'more': 73,\n",
              " 'much': 312,\n",
              " 'my': 11,\n",
              " 'myself': 382,\n",
              " 'name': 220,\n",
              " 'need': 340,\n",
              " 'never': 14,\n",
              " 'new': 244,\n",
              " 'next': 338,\n",
              " 'night': 92,\n",
              " 'no': 55,\n",
              " 'not': 336,\n",
              " 'nothing': 42,\n",
              " 'now': 182,\n",
              " 'of': 17,\n",
              " 'oh': 172,\n",
              " 'old': 253,\n",
              " 'on': 100,\n",
              " 'one': 139,\n",
              " 'only': 190,\n",
              " 'ooh': 36,\n",
              " 'open': 293,\n",
              " 'or': 108,\n",
              " 'other': 141,\n",
              " 'our': 112,\n",
              " 'out': 43,\n",
              " 'outside': 147,\n",
              " 'over': 79,\n",
              " 'pay': 300,\n",
              " 'piece': 278,\n",
              " 'pitch': 280,\n",
              " 'play': 334,\n",
              " 'played': 52,\n",
              " 'pour': 163,\n",
              " 'pretend': 335,\n",
              " 'rain': 122,\n",
              " 'raised': 260,\n",
              " 'reaching': 192,\n",
              " 'read': 383,\n",
              " 'reap': 302,\n",
              " 'regrets': 269,\n",
              " 'remember': 81,\n",
              " 'remind': 200,\n",
              " 'reminded': 189,\n",
              " 'right': 168,\n",
              " 'rolling': 24,\n",
              " 'rose': 351,\n",
              " 'run': 345,\n",
              " 'running': 331,\n",
              " 'sad': 179,\n",
              " 'said': 82,\n",
              " 'saved': 356,\n",
              " 'say': 54,\n",
              " 'scared': 212,\n",
              " 'scars': 115,\n",
              " 'screaming': 219,\n",
              " 'secret': 329,\n",
              " 'security': 230,\n",
              " 'see': 75,\n",
              " 'seem': 146,\n",
              " 'sell': 195,\n",
              " 'set': 121,\n",
              " 'settled': 245,\n",
              " 'shared': 288,\n",
              " 'she': 251,\n",
              " 'ship': 276,\n",
              " 'shit': 277,\n",
              " 'side': 89,\n",
              " 'since': 344,\n",
              " 'slave': 236,\n",
              " 'so': 60,\n",
              " 'some': 95,\n",
              " 'someone': 109,\n",
              " 'something': 377,\n",
              " 'sometimes': 32,\n",
              " 'sorrow': 297,\n",
              " 'sorry': 57,\n",
              " 'soul': 291,\n",
              " 'sow': 303,\n",
              " 'speak': 342,\n",
              " 'stand': 362,\n",
              " 'starting': 191,\n",
              " 'stay': 133,\n",
              " 'still': 380,\n",
              " 'story': 281,\n",
              " 'strong': 357,\n",
              " 'stupid': 231,\n",
              " 'such': 320,\n",
              " 'summer': 261,\n",
              " 'sun': 223,\n",
              " 'supposed': 309,\n",
              " 'sure': 105,\n",
              " 'surprise': 264,\n",
              " 'take': 158,\n",
              " 'talk': 77,\n",
              " 'tear': 152,\n",
              " 'tell': 45,\n",
              " 'than': 74,\n",
              " 'that': 9,\n",
              " 'the': 3,\n",
              " 'their': 225,\n",
              " 'there': 103,\n",
              " 'these': 306,\n",
              " 'they': 50,\n",
              " 'things': 106,\n",
              " 'think': 284,\n",
              " 'thinking': 201,\n",
              " 'this': 46,\n",
              " 'thousand': 143,\n",
              " 'threw': 375,\n",
              " 'through': 292,\n",
              " 'throw': 290,\n",
              " 'time': 59,\n",
              " 'times': 144,\n",
              " 'to': 4,\n",
              " 'told': 282,\n",
              " 'tomorrow': 215,\n",
              " 'too': 360,\n",
              " 'touched': 164,\n",
              " 'town': 328,\n",
              " 'treasured': 298,\n",
              " 'treat': 173,\n",
              " 'tried': 149,\n",
              " 'true': 101,\n",
              " 'turn': 131,\n",
              " 'two': 134,\n",
              " 'typical': 325,\n",
              " 'underestimate': 279,\n",
              " 'uninvited': 186,\n",
              " 'until': 353,\n",
              " 'up': 132,\n",
              " 'us': 65,\n",
              " 'use': 157,\n",
              " 'used': 316,\n",
              " 'vicious': 348,\n",
              " 'waiting': 381,\n",
              " 'wake': 378,\n",
              " 'walk': 104,\n",
              " 'wanna': 97,\n",
              " 'want': 29,\n",
              " 'was': 84,\n",
              " 'wash': 239,\n",
              " 'waste': 165,\n",
              " 'watched': 162,\n",
              " 'way': 44,\n",
              " 'we': 21,\n",
              " 'weak': 361,\n",
              " 'well': 130,\n",
              " 'were': 85,\n",
              " 'what': 53,\n",
              " 'when': 66,\n",
              " 'where': 211,\n",
              " 'while': 91,\n",
              " 'who': 135,\n",
              " 'whole': 175,\n",
              " 'why': 183,\n",
              " 'wide': 176,\n",
              " 'will': 199,\n",
              " 'win': 218,\n",
              " 'wish': 23,\n",
              " 'with': 47,\n",
              " 'without': 364,\n",
              " 'wondering': 304,\n",
              " 'word': 332,\n",
              " 'work': 237,\n",
              " 'world': 129,\n",
              " 'worries': 267,\n",
              " 'would': 113,\n",
              " 'wrong': 214,\n",
              " 'ya': 311,\n",
              " 'yeah': 56,\n",
              " 'years': 307,\n",
              " 'yesterday': 257,\n",
              " 'you': 2,\n",
              " 'younger': 317,\n",
              " 'your': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-QAlONkICUb"
      },
      "source": [
        "embedded_vector=tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwhaenC9IaeA"
      },
      "source": [
        "#embedded_vector[0]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sgHUtIPMrw"
      },
      "source": [
        "datalist = []\n",
        "for d in embedded_vector:\n",
        "  if len(d)>1:\n",
        "    for i in range(2, len(d)):\n",
        "      datalist.append(d[:i])\n",
        "      #print(d[:i])"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmN6ZFRoPM46"
      },
      "source": [
        "max_length = 20\n",
        "sequences = pad_sequences(datalist, maxlen=max_length, padding='pre')\n",
        "#sequences"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9XDEEjZIfd1"
      },
      "source": [
        "embedded_vector=np.array(embedded_vector)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEw-M-aQIxJW",
        "outputId": "0f4fe8d8-aaab-48ee-f175-ffd652db31f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "embedded_vector[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 96,  20,  95, 386, 123,  11,  44,  93,   3,  92,  16,   9, 385,\n",
              "       384,   2, 383,   3,   1, 221,   2,  47])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arK5ZGkvIzhD"
      },
      "source": [
        "#X,y=embedded_vector[:,:-1],embedded_vector[:,-1]\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwu3GnwNJU8j"
      },
      "source": [
        "vocab_size=len(tokenizer.word_index)+1"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Prfjh5JnrS",
        "outputId": "5000f974-bd9e-4d2a-9af9-d7181648ad9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk6aEWa8Jy89"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zejo-k7jKM9q",
        "outputId": "c1c6c593-2519-4750-bde5-92308d85c47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape[1]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRoEVNUKQHm"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,20,input_length=seq_length))\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV3ZCk57V5dO",
        "outputId": "5dec48f1-224f-4912-d962-e1e157fc3148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 19, 20)            7740      \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 19, 100)           48400     \n",
            "_________________________________________________________________\n",
            "lstm_13 (LSTM)               (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 387)               39087     \n",
            "=================================================================\n",
            "Total params: 185,727\n",
            "Trainable params: 185,727\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry53VTJ9LTkD"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoY7DipcMBBK",
        "outputId": "96ccd40f-a7cd-4473-a272-55e8753ae650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X,y,batch_size=32,epochs=120)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 4.6145 - accuracy: 0.0835\n",
            "Epoch 2/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 3.1091 - accuracy: 0.2557\n",
            "Epoch 3/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 2.1409 - accuracy: 0.4594\n",
            "Epoch 4/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 1.5149 - accuracy: 0.6198\n",
            "Epoch 5/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 1.0949 - accuracy: 0.7322\n",
            "Epoch 6/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.8284 - accuracy: 0.7974\n",
            "Epoch 7/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 1.2480 - accuracy: 0.7048\n",
            "Epoch 8/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 1.5971 - accuracy: 0.5884\n",
            "Epoch 9/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.8256 - accuracy: 0.7975\n",
            "Epoch 10/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.5671 - accuracy: 0.8608\n",
            "Epoch 11/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.4553 - accuracy: 0.8830\n",
            "Epoch 12/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3923 - accuracy: 0.8968\n",
            "Epoch 13/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3544 - accuracy: 0.9036\n",
            "Epoch 14/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3259 - accuracy: 0.9085\n",
            "Epoch 15/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3042 - accuracy: 0.9129\n",
            "Epoch 16/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2890 - accuracy: 0.9160\n",
            "Epoch 17/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.2771 - accuracy: 0.9189\n",
            "Epoch 18/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.2613 - accuracy: 0.9223\n",
            "Epoch 19/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2539 - accuracy: 0.9238\n",
            "Epoch 20/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2418 - accuracy: 0.9265\n",
            "Epoch 21/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2347 - accuracy: 0.9290\n",
            "Epoch 22/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.2267 - accuracy: 0.9295\n",
            "Epoch 23/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2222 - accuracy: 0.9307\n",
            "Epoch 24/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2145 - accuracy: 0.9332\n",
            "Epoch 25/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.2108 - accuracy: 0.9339\n",
            "Epoch 26/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2047 - accuracy: 0.9352\n",
            "Epoch 27/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2022 - accuracy: 0.9363\n",
            "Epoch 28/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1983 - accuracy: 0.9359\n",
            "Epoch 29/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.1925 - accuracy: 0.9383\n",
            "Epoch 30/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2076 - accuracy: 0.9361\n",
            "Epoch 31/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1936 - accuracy: 0.9383\n",
            "Epoch 32/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2082 - accuracy: 0.9358\n",
            "Epoch 33/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.2090 - accuracy: 0.9336\n",
            "Epoch 34/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1975 - accuracy: 0.9361\n",
            "Epoch 35/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2009 - accuracy: 0.9351\n",
            "Epoch 36/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1926 - accuracy: 0.9365\n",
            "Epoch 37/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1893 - accuracy: 0.9376\n",
            "Epoch 38/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1816 - accuracy: 0.9398\n",
            "Epoch 39/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1764 - accuracy: 0.9409\n",
            "Epoch 40/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1845 - accuracy: 0.9382\n",
            "Epoch 41/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1747 - accuracy: 0.9409\n",
            "Epoch 42/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1726 - accuracy: 0.9423\n",
            "Epoch 43/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1743 - accuracy: 0.9406\n",
            "Epoch 44/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1726 - accuracy: 0.9400\n",
            "Epoch 45/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1734 - accuracy: 0.9406\n",
            "Epoch 46/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1674 - accuracy: 0.9434\n",
            "Epoch 47/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1693 - accuracy: 0.9408\n",
            "Epoch 48/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1855 - accuracy: 0.9379\n",
            "Epoch 49/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1707 - accuracy: 0.9419\n",
            "Epoch 50/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1633 - accuracy: 0.9426\n",
            "Epoch 51/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1638 - accuracy: 0.9432\n",
            "Epoch 52/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1677 - accuracy: 0.9418\n",
            "Epoch 53/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1650 - accuracy: 0.9424\n",
            "Epoch 54/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1627 - accuracy: 0.9425\n",
            "Epoch 55/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1595 - accuracy: 0.9434\n",
            "Epoch 56/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1592 - accuracy: 0.9443\n",
            "Epoch 57/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1604 - accuracy: 0.9442\n",
            "Epoch 58/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1581 - accuracy: 0.9444\n",
            "Epoch 59/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1600 - accuracy: 0.9446\n",
            "Epoch 60/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1626 - accuracy: 0.9430\n",
            "Epoch 61/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1585 - accuracy: 0.9437\n",
            "Epoch 62/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1579 - accuracy: 0.9443\n",
            "Epoch 63/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1588 - accuracy: 0.9434\n",
            "Epoch 64/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.1530 - accuracy: 0.9453\n",
            "Epoch 65/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1550 - accuracy: 0.9446\n",
            "Epoch 66/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1522 - accuracy: 0.9452\n",
            "Epoch 67/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1525 - accuracy: 0.9453\n",
            "Epoch 68/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1547 - accuracy: 0.9450\n",
            "Epoch 69/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.1537 - accuracy: 0.9446\n",
            "Epoch 70/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1580 - accuracy: 0.9430\n",
            "Epoch 71/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.1902 - accuracy: 0.9371\n",
            "Epoch 72/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.1789 - accuracy: 0.9385\n",
            "Epoch 73/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2565 - accuracy: 0.9256\n",
            "Epoch 74/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.1953 - accuracy: 0.9349\n",
            "Epoch 75/120\n",
            "1177/1177 [==============================] - 8s 6ms/step - loss: 0.1562 - accuracy: 0.9446\n",
            "Epoch 76/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1546 - accuracy: 0.9438\n",
            "Epoch 77/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1548 - accuracy: 0.9430\n",
            "Epoch 78/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1694 - accuracy: 0.9396\n",
            "Epoch 79/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1595 - accuracy: 0.9434\n",
            "Epoch 80/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1572 - accuracy: 0.9430\n",
            "Epoch 81/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1540 - accuracy: 0.9448\n",
            "Epoch 82/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1742 - accuracy: 0.9397\n",
            "Epoch 83/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1620 - accuracy: 0.9413\n",
            "Epoch 84/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1527 - accuracy: 0.9445\n",
            "Epoch 85/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1533 - accuracy: 0.9441\n",
            "Epoch 86/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1531 - accuracy: 0.9438\n",
            "Epoch 87/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1522 - accuracy: 0.9437\n",
            "Epoch 88/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1552 - accuracy: 0.9438\n",
            "Epoch 89/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1528 - accuracy: 0.9440\n",
            "Epoch 90/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1502 - accuracy: 0.9443\n",
            "Epoch 91/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1474 - accuracy: 0.9458\n",
            "Epoch 92/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1500 - accuracy: 0.9446\n",
            "Epoch 93/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1479 - accuracy: 0.9454\n",
            "Epoch 94/120\n",
            "1177/1177 [==============================] - 9s 7ms/step - loss: 0.1474 - accuracy: 0.9455\n",
            "Epoch 95/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1469 - accuracy: 0.9464\n",
            "Epoch 96/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1466 - accuracy: 0.9453\n",
            "Epoch 97/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1477 - accuracy: 0.9453\n",
            "Epoch 98/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1471 - accuracy: 0.9451\n",
            "Epoch 99/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1485 - accuracy: 0.9438\n",
            "Epoch 100/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.1504 - accuracy: 0.9441\n",
            "Epoch 101/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1472 - accuracy: 0.9450\n",
            "Epoch 102/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1455 - accuracy: 0.9454\n",
            "Epoch 103/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1469 - accuracy: 0.9451\n",
            "Epoch 104/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1492 - accuracy: 0.9454\n",
            "Epoch 105/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1476 - accuracy: 0.9456\n",
            "Epoch 106/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1427 - accuracy: 0.9462\n",
            "Epoch 107/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1434 - accuracy: 0.9453\n",
            "Epoch 108/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1447 - accuracy: 0.9464\n",
            "Epoch 109/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1441 - accuracy: 0.9464\n",
            "Epoch 110/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1433 - accuracy: 0.9464\n",
            "Epoch 111/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.1487 - accuracy: 0.9449\n",
            "Epoch 112/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1423 - accuracy: 0.9467\n",
            "Epoch 113/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1456 - accuracy: 0.9447\n",
            "Epoch 114/120\n",
            "1177/1177 [==============================] - 8s 7ms/step - loss: 0.1500 - accuracy: 0.9448\n",
            "Epoch 115/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.1451 - accuracy: 0.9451\n",
            "Epoch 116/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3636 - accuracy: 0.9027\n",
            "Epoch 117/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.3221 - accuracy: 0.9069\n",
            "Epoch 118/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2530 - accuracy: 0.9228\n",
            "Epoch 119/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2234 - accuracy: 0.9286\n",
            "Epoch 120/120\n",
            "1177/1177 [==============================] - 7s 6ms/step - loss: 0.2118 - accuracy: 0.9316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa00b7b9278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYhE3KPpMLKF"
      },
      "source": [
        "poetry_length = 10\n",
        "def generate_poetry(seed_text, n_lines):\n",
        "  for i in range(n_lines):\n",
        "    text = []\n",
        "    for _ in range(poetry_length):\n",
        "      encoded = tokenizer.texts_to_sequences([seed_text])\n",
        "      encoded = pad_sequences(encoded, maxlen=seq_length, padding='pre')\n",
        "\n",
        "      y_pred = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "      predicted_word = \"\"\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "        if index == y_pred:\n",
        "          predicted_word = word\n",
        "          break\n",
        "\n",
        "      seed_text = seed_text + ' ' + predicted_word\n",
        "      text.append(predicted_word)\n",
        "\n",
        "    seed_text = text[-1]\n",
        "    text = ' '.join(text)\n",
        "    print(text)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3-8Cm6OMn0p",
        "outputId": "7e896d42-9d10-448c-c8fe-c6c6a6054b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "seed_text = 'i love you'\n",
        "generate_poetry(seed_text, 5)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "treat your girl that i can give you all the\n",
            "beat are gonna rolling in the i have no story\n",
            "to make love to you love to ooh baby love\n",
            "to yeah and i can tell by the way you\n",
            "never had met rolling in the deep are gonna rolling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FiYj1gAMu0C",
        "outputId": "c954abb1-106c-4686-ff17-93a1ad9597f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "seed_text = 'i have no story'\n",
        "generate_poetry(seed_text, 5)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to be told but heard one on you and gonna\n",
            "wish you never had met rolling in the deep are\n",
            "gonna rolling in the i have no story to be\n",
            "home hello from the outside at least i can say\n",
            "that maybe you could help me ease my mind i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiHL8kzhU0j6",
        "outputId": "1a3d5aa0-3a81-4054-9aa8-91167ceaeb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 93.881345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkfyPeUDM40k"
      },
      "source": [
        ""
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoOs5AEnNEM1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}